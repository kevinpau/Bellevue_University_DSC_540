{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Week 6: Midterm Project\n",
    " File: DSC540_Paulovici_Midterm.py (.ipynb)<br>\n",
    " Name: Kevin Paulovici<br>\n",
    " Date: 1/19/2020<br>\n",
    " Course: DSC 540 Data Preparation (2203-1)<br>\n",
    " Assignment: Midterm Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Tasks\n",
    " 1) Replace headers (Data Wrangling with Python pg. 154 – 163) <br>\n",
    " 2) Format Data to a Readable Format (Data Wrangling with Python pg. 164 – 168) <br>\n",
    " 3) Identify outliers and bad data (Data Wrangling with Python pg. 169 – 174) <br>\n",
    " 4) Find Duplicates (Data Wrangling with Python pg. 175 – 178) <br>\n",
    " 5) Conduct Fuzzy Matching (if you don’t have an obvious example to do this with in your data, create categories and use Fuzzy Matching to lump data together) (Data Wrangling with Python pg. 179 – 188) <br>\n",
    " Summary - A 250-word paper summarizing your steps and any challenges you ran into during the project. You should also outline any decisions you had to make while transforming the data (for example, if you decided to remove duplicates, how did you arrive at that decision?)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Database Info\n",
    " Dataset: pokemon.csv retrieved from https://www.kaggle.com/rounakbanik/pokemon <br>\n",
    " Note: The dataset contains 802 rows, this was extended to more than the required 1000. This was also done for #4 of the assignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from csv import DictReader\n",
    "import pprint\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Part 1 - Replace headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('abilities', \"['Overgrow', 'Chlorophyll']\"),\n",
      "             ('against_bug', '1'),\n",
      "             ('against_dark', '1'),\n",
      "             ('against_dragon', '1'),\n",
      "             ('against_electric', '0.5'),\n",
      "             ('against_fairy', '0.5'),\n",
      "             ('against_fight', '0.5'),\n",
      "             ('against_fire', '2'),\n",
      "             ('against_flying', '2'),\n",
      "             ('against_ghost', '1'),\n",
      "             ('against_grass', '0.25'),\n",
      "             ('against_ground', '1'),\n",
      "             ('against_ice', '2'),\n",
      "             ('against_normal', '1'),\n",
      "             ('against_poison', '1'),\n",
      "             ('against_psychic', '2'),\n",
      "             ('against_rock', '1'),\n",
      "             ('against_steel', '1'),\n",
      "             ('against_water', '0.5'),\n",
      "             ('attack', '49'),\n",
      "             ('base_egg_steps', '5120'),\n",
      "             ('base_happiness', '70'),\n",
      "             ('base_total', '318'),\n",
      "             ('capture_rate', '45'),\n",
      "             ('classfication', 'Seed PokÃ©mon'),\n",
      "             ('defense', '49'),\n",
      "             ('experience_growth', '1059860'),\n",
      "             ('height_m', '0.7'),\n",
      "             ('hp', '45'),\n",
      "             ('japanese_name',\n",
      "              'Fushigidaneã\\x83\\x95ã\\x82·ã\\x82®ã\\x83\\x80ã\\x83\\x8d'),\n",
      "             ('name', 'Bulbasaur'),\n",
      "             ('percentage_male', '88.1'),\n",
      "             ('pokedex_number', '1'),\n",
      "             ('sp_attack', '65'),\n",
      "             ('sp_defense', '65'),\n",
      "             ('speed', '45'),\n",
      "             ('type1', 'grass'),\n",
      "             ('type2', 'poison'),\n",
      "             ('weight_kg', '6.9'),\n",
      "             ('generation', '1'),\n",
      "             ('is_legendary', '0')])\n"
     ]
    }
   ],
   "source": [
    "# open the dataset wiith DictReader\n",
    "poke_data = DictReader(open('pokemon_data.csv', encoding='ISO-8859-1'))\n",
    "\n",
    "# create list of all rows\n",
    "poke_rows = [d for d in poke_data]\n",
    "\n",
    "pprint.pprint(poke_rows[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" After looking at the headers, we can replace the \"against_\" col names with something\n",
    "else, say \"facing_\". \n",
    "So, we need to make a dict of headers to replace. \n",
    "1) Find the the write headers\n",
    "2) Add as a key to dict, replacement in value \n",
    "\"\"\"\n",
    "new_headers = {} \n",
    "\n",
    "for data_dict in poke_rows:\n",
    "    for dkey, dval in data_dict.items():\n",
    "        # determine if it is a header we want to replace\n",
    "        if \"against_\" in dkey:\n",
    "            new_headers[dkey] = dkey.replace(\"against_\", \"facing_\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'abilities': \"['Overgrow', 'Chlorophyll']\",\n",
      " 'attack': '49',\n",
      " 'base_egg_steps': '5120',\n",
      " 'base_happiness': '70',\n",
      " 'base_total': '318',\n",
      " 'capture_rate': '45',\n",
      " 'classfication': 'Seed PokÃ©mon',\n",
      " 'defense': '49',\n",
      " 'experience_growth': '1059860',\n",
      " 'facing_bug': '1',\n",
      " 'facing_dark': '1',\n",
      " 'facing_dragon': '1',\n",
      " 'facing_electric': '0.5',\n",
      " 'facing_fairy': '0.5',\n",
      " 'facing_fight': '0.5',\n",
      " 'facing_fire': '2',\n",
      " 'facing_flying': '2',\n",
      " 'facing_ghost': '1',\n",
      " 'facing_grass': '0.25',\n",
      " 'facing_ground': '1',\n",
      " 'facing_ice': '2',\n",
      " 'facing_normal': '1',\n",
      " 'facing_poison': '1',\n",
      " 'facing_psychic': '2',\n",
      " 'facing_rock': '1',\n",
      " 'facing_steel': '1',\n",
      " 'facing_water': '0.5',\n",
      " 'generation': '1',\n",
      " 'height_m': '0.7',\n",
      " 'hp': '45',\n",
      " 'is_legendary': '0',\n",
      " 'japanese_name': 'Fushigidaneã\\x83\\x95ã\\x82·ã\\x82®ã\\x83\\x80ã\\x83\\x8d',\n",
      " 'name': 'Bulbasaur',\n",
      " 'percentage_male': '88.1',\n",
      " 'pokedex_number': '1',\n",
      " 'sp_attack': '65',\n",
      " 'sp_defense': '65',\n",
      " 'speed': '45',\n",
      " 'type1': 'grass',\n",
      " 'type2': 'poison',\n",
      " 'weight_kg': '6.9'}\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Search through the dicition, when headers are found that need to be replace. \n",
    "Otherwise, leave data as is\n",
    "\"\"\"\n",
    "new_poke_rows = []\n",
    "\n",
    "for data_dict in poke_rows:\n",
    "    new_row = {}\n",
    "    for dkey, dval in data_dict.items():\n",
    "        if dkey in new_headers.keys():\n",
    "            new_row[new_headers[dkey]] = dval\n",
    "        else:\n",
    "            new_row[dkey] = dval\n",
    "    new_poke_rows.append(new_row)\n",
    "\n",
    "pprint.pprint(new_poke_rows[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Part 2 - Format Data to a Readable Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********* New Pokemon *********\n",
      "attack: 49\n",
      "defense: 49\n",
      "hp: 45\n",
      "name: Bulbasaur\n",
      "speed: 45\n",
      "type1: grass\n",
      "type2: poison\n",
      "********* New Pokemon *********\n",
      "attack: 60\n",
      "defense: 40\n",
      "hp: 45\n",
      "name: Torchic\n",
      "speed: 45\n",
      "type1: fire\n",
      "type2: \n",
      "********* New Pokemon *********\n",
      "attack: 75\n",
      "defense: 50\n",
      "hp: 70\n",
      "name: Stufful\n",
      "speed: 50\n",
      "type1: normal\n",
      "type2: fighting\n"
     ]
    }
   ],
   "source": [
    "\"\"\" pprint does provide a fairly clean format as is, however, there is too much data\n",
    "for general viewing. Let's pick out a select few by searching for them in the newly created data set.\n",
    "Note - As an example, we don't need to print out all data rows, we'll show a few.\n",
    "\"\"\"\n",
    "# create list of data to show\n",
    "select_data = \"name type1 type2 hp speed attack defense\".split()\n",
    "count = 0\n",
    "\n",
    "for data_dict in new_poke_rows:\n",
    "    if count == 0 or count == 254 or count == 758:\n",
    "        print(\"********* New Pokemon *********\")\n",
    "\n",
    "    for dkey, dval in data_dict.items():\n",
    "        for s in select_data:\n",
    "            if s == dkey:\n",
    "                if count == 0 or count == 254 or count == 758:\n",
    "                    print(\"{}: {}\".format(dkey, dval))\n",
    "    \n",
    "    count += 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Part 3 - Identify outliers and bad data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 97 legendary Pokemon\n",
      "There are 963 non-legendary Pokemon\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Given the data, there is expected to be a large variety of ranges in the stats of each\n",
    "pokemone (e.g., hp can vary from low to high values). However, we identify outliers that \n",
    "we may or may not want to keep. is_legendary is column to check if a pokemon is legendary. \n",
    "You can argue either way to keep or discard it. For now, I'll just be finding which are legendary.\n",
    "\"\"\"\n",
    "legendary = 0\n",
    "non_legendary = 0\n",
    "# is_legendary = 1, yes\n",
    "# is_legendary = 0, no\n",
    "for data_dict in new_poke_rows:\n",
    "    for dkey, dval in data_dict.items():\n",
    "        if dkey == \"is_legendary\":\n",
    "            if dval == \"1\":\n",
    "                legendary += 1\n",
    "            else:\n",
    "                non_legendary += 1\n",
    "\n",
    "print(\"There are {} legendary Pokemon\".format(legendary))\n",
    "print(\"There are {} non-legendary Pokemon\".format(non_legendary))\n",
    "\n",
    "# We can see ~10% of the Pokemon can be considered outliers.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Part 4 - Find Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 259 duplicates\n"
     ]
    }
   ],
   "source": [
    "\"\"\" First we'll check to see if there are any duplicates based on the name col. Other cols will have duplicates and that is expected (e.g., type1 - there is a limited number of options).\n",
    "\"\"\"\n",
    "# \n",
    "unique = [] \n",
    "duplicate = 0\n",
    "\n",
    "for data_dict in new_poke_rows:\n",
    "    if data_dict[\"name\"] in unique:\n",
    "        duplicate += 1\n",
    "    else:\n",
    "        unique.append(data_dict[\"name\"])\n",
    "\n",
    "print(\"There are {} duplicates\".format(duplicate))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 0 duplicates\n"
     ]
    }
   ],
   "source": [
    "# One way to handle this is to not include them in the new_poke_rows data, so lets \n",
    "# adjust the creation of these to exclude them from the beginning\n",
    "\n",
    "new_poke_rows = []\n",
    "unique = [] \n",
    "\n",
    "for data_dict in poke_rows:\n",
    "    if data_dict[\"name\"] in unique:\n",
    "        pass\n",
    "\n",
    "    else:\n",
    "        new_row = {}\n",
    "        for dkey, dval in data_dict.items():\n",
    "            if dkey in new_headers.keys():\n",
    "                new_row[new_headers[dkey]] = dval\n",
    "            else:\n",
    "                new_row[dkey] = dval\n",
    "        new_poke_rows.append(new_row)\n",
    "\n",
    "        unique.append(data_dict[\"name\"])\n",
    "\n",
    "# now we can re-run the previous loop to check\n",
    "duplicate = 0\n",
    "unique = []\n",
    "\n",
    "for data_dict in new_poke_rows:\n",
    "    if data_dict[\"name\"] in unique:\n",
    "        duplicate += 1\n",
    "    else:\n",
    "        unique.append(data_dict[\"name\"])\n",
    "\n",
    "print(\"There are {} duplicates\".format(duplicate))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Part 5 - Conduct Fuzzy Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fuzzywuzzy import fuzz\n",
    "import random\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'abilities': \"['Blaze', 'Solar Power']\",\n",
      " 'attack': '52',\n",
      " 'base_egg_steps': '5120',\n",
      " 'base_happiness': '70',\n",
      " 'base_total': '309',\n",
      " 'capture_rate': '45',\n",
      " 'classfication': 'Lizard PokÃ©mon',\n",
      " 'defense': '43',\n",
      " 'experience_growth': '1059860',\n",
      " 'facing_bug': '0.5',\n",
      " 'facing_dark': '1',\n",
      " 'facing_dragon': '1',\n",
      " 'facing_electric': '1',\n",
      " 'facing_fairy': '0.5',\n",
      " 'facing_fight': '1',\n",
      " 'facing_fire': '0.5',\n",
      " 'facing_flying': '1',\n",
      " 'facing_ghost': '1',\n",
      " 'facing_grass': '0.5',\n",
      " 'facing_ground': '2',\n",
      " 'facing_ice': '0.5',\n",
      " 'facing_normal': '1',\n",
      " 'facing_poison': '1',\n",
      " 'facing_psychic': '1',\n",
      " 'facing_rock': '2',\n",
      " 'facing_steel': '0.5',\n",
      " 'facing_water': '2',\n",
      " 'generation': '1',\n",
      " 'height_m': '0.6',\n",
      " 'hp': '39',\n",
      " 'is_legendary': '0',\n",
      " 'japanese_name': 'Hitokageã\\x83\\x92ã\\x83\\x88ã\\x82«ã\\x82²',\n",
      " 'name': 'Charmander',\n",
      " 'percentage_male': '88.1',\n",
      " 'pokedex_number': '4',\n",
      " 'sp_attack': '60',\n",
      " 'sp_defense': '50',\n",
      " 'speed': '65',\n",
      " 'type1': 'fire',\n",
      " 'type2': 'FIRE',\n",
      " 'weight_kg': '8.5'}\n"
     ]
    }
   ],
   "source": [
    "\"\"\" To mimic fuzzy matching, I'm going to use a subset of my data, specifically Type2 == \"\".\n",
    "Then I'm going to fill the missing spots with variations of \"fire\" and test how they compare to \"fire\". I'm also going to exlcude duplicates.\n",
    "\"\"\"\n",
    "variations = [\"FIRE\", \"fire type\", \"Fire\"]\n",
    "\n",
    "sub_poke_rows = []\n",
    "unique = [] \n",
    "\n",
    "for data_dict in poke_rows:\n",
    "    if data_dict[\"name\"] in unique:\n",
    "        pass\n",
    "    elif data_dict[\"type2\"] != \"\":\n",
    "        pass \n",
    "    else:\n",
    "        type2 = random.choice(variations)\n",
    "        new_row = {}\n",
    "        for dkey, dval in data_dict.items():\n",
    "            if dkey in new_headers.keys():\n",
    "                new_row[new_headers[dkey]] = dval\n",
    "            elif dkey == \"type2\":\n",
    "                new_row[dkey] = type2\n",
    "            else:\n",
    "                new_row[dkey] = dval\n",
    "        sub_poke_rows.append(new_row)\n",
    "\n",
    "pprint.pprint(sub_poke_rows[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO - The above code sets up the fuzzy matching, additional code should be added to seach through the sub_poke_rows for all variations. I'm assuming I found them and continuing on the fuzzy matching\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The ratio for FIRE and fire is: 0\n",
      "The ratio for fire type and fire is: 62\n",
      "The ratio for Fire and fire is: 75\n"
     ]
    }
   ],
   "source": [
    "# Fuzzy matching\n",
    "# TODO - A more detailed loop should be implemented to check more variations then the subset I'm looking at.\n",
    "\n",
    "compare = \"fire\"\n",
    "\n",
    "# ratio\n",
    "for v in variations:\n",
    "    ratio = fuzz.ratio(v, compare)\n",
    "    print(\"The ratio for {} and {} is: {}\".format(v, compare, ratio))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The partial ratio for FIRE and fire is: 0\n",
      "The partial ratio for fire type and fire is: 100\n",
      "The partial ratio for Fire and fire is: 75\n"
     ]
    }
   ],
   "source": [
    "# partial ratio\n",
    "for v in variations:\n",
    "    ratio = fuzz.partial_ratio(v, compare)\n",
    "    print(\"The partial ratio for {} and {} is: {}\".format(v, compare, ratio))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The token sort ratio for FIRE and fire is: 100\n",
      "The token sort ratio for fire type and fire is: 62\n",
      "The token sort ratio for Fire and fire is: 100\n"
     ]
    }
   ],
   "source": [
    "# token sort ratio\n",
    "for v in variations:\n",
    "    ratio = fuzz.token_sort_ratio(v, compare)\n",
    "    print(\"The token sort ratio for {} and {} is: {}\".format(v, compare, ratio))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The token set ratio for FIRE and fire is: 100\n",
      "The token set ratio for fire type and fire is: 100\n",
      "The token set ratio for Fire and fire is: 100\n"
     ]
    }
   ],
   "source": [
    "# token set ratio\n",
    "for v in variations:\n",
    "    ratio = fuzz.token_set_ratio(v, compare)\n",
    "    print(\"The token set ratio for {} and {} is: {}\".format(v, compare, ratio))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " See DSC540_Paulovici_Midterm_summary.docx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
